{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82643047",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce128ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB #다항분포 나이브 베이즈 모델\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score #정확도 계산\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55d6f2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "  index_to_word[index]=token\n",
    "# print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "407a8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtmvector = CountVectorizer()\n",
    "def reuters_load_ml(num_words, mode = True):#mode true는 dtm, false는 tfidf\n",
    "    (x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=num_words, test_split=0.2)\n",
    "    decoded = []\n",
    "    for i in range(len(x_train)):\n",
    "        t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "        decoded.append(t)\n",
    "\n",
    "    x_train = decoded\n",
    "    decoded = []\n",
    "    for i in range(len(x_test)):\n",
    "        t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "        decoded.append(t)\n",
    "    x_test = decoded\n",
    "    if mode :\n",
    "        x_train = dtmvector.fit_transform(x_train)\n",
    "        x_test = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "    else :\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "        x_train = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "        x_test_dtm = dtmvector.transform(x_test) #테스트 데이터를 DTM으로 변환\n",
    "        x_test = tfidf_transformer.transform(x_test_dtm) #DTM을 TF-IDF 행렬로 변환\n",
    "        \n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63d7820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ml(x_train, y_train, x_test, y_test) :\n",
    "    #NB\n",
    "    model = MultinomialNB()\n",
    "    model.fit(x_train, y_train)\n",
    "    predicted = model.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"NB 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "    \n",
    "    #CNB\n",
    "    cb = ComplementNB()\n",
    "    cb.fit(x_train, y_train)\n",
    "    predicted = cb.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"CNB 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "    \n",
    "    #로지스틱회귀\n",
    "    lr = LogisticRegression(C=10000, penalty='l2', max_iter=3000)\n",
    "    lr.fit(x_train, y_train)\n",
    "    predicted = lr.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"로지스틱회귀 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "    \n",
    "    #svc\n",
    "    lsvc = LinearSVC(C=1000, penalty='l1', max_iter=3000, dual=False)\n",
    "    lsvc.fit(x_train, y_train)\n",
    "    predicted = lsvc.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"SVC 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "    \n",
    "    #tree\n",
    "    tree = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "    tree.fit(x_train, y_train)\n",
    "    predicted = tree.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"tree 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "    \n",
    "    #RandomForest\n",
    "    forest = RandomForestClassifier(n_estimators =5, random_state=0)\n",
    "    forest.fit(x_train, y_train)\n",
    "    predicted = forest.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"RandomForest 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "    \n",
    "    #GradientBoosting\n",
    "    grbt = GradientBoostingClassifier(random_state=0) # verbose=3\n",
    "    grbt.fit(x_train, y_train)\n",
    "    predicted = grbt.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"GradientBoosting 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교\n",
    "\n",
    "    #보팅\n",
    "    voting_classifier = VotingClassifier(estimators=[('lr', lr), ('cb', cb), ('gnb', grbt)],voting='soft')\n",
    "    voting_classifier.fit(x_train, y_train)\n",
    "    predicted = voting_classifier.predict(x_test) #테스트 데이터에 대한 예측\n",
    "    print(\"보팅 정확도:\", accuracy_score(y_test, predicted)) #예측값과 실제값 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd779b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_words=None, DTM을 활용한 정확도\n",
      "NB 정확도: 0.7226179875333927\n",
      "CNB 정확도: 0.7782724844167409\n"
     ]
    }
   ],
   "source": [
    "print(\"num_words=None, DTM을 활용한 정확도\") \n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(None,True)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "print(\"num_words=None, TFIDF을 활용한 정확도\") \n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(None,False)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "print(\"num_words=10000, DTM을 활용한 정확도\") \n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(10000,True)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "print(\"num_words=10000, TFIDF을 활용한 정확도\") \n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(10000,False)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "print(\"num_words=5000, DTM을 활용한 정확도\") \n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(5000,True)\n",
    "fit_ml(x_train, y_train, x_test, y_test)\n",
    "print(\"num_words=5000, TFIDF을 활용한 정확도\") \n",
    "x_train, y_train, x_test, y_test = reuters_load_ml(5000,False)\n",
    "fit_ml(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642f17f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(classification_report(y_test, model.predict(x_test_dtm), zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4e96c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def graph_confusion_matrix(model, x_test, y_test):#, classes_name):\n",
    "  df_cm = pd.DataFrame(confusion_matrix(y_test, model.predict(x_test)))#, index=classes_name, columns=classes_name)\n",
    "  fig = plt.figure(figsize=(15,15))\n",
    "  heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "  heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n",
    "  heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=12)\n",
    "  plt.ylabel('label')\n",
    "  plt.xlabel('predicted value')\n",
    "\n",
    "# graph_confusion_matrix(model, x_test_dtm, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3487c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Reuters 데이터셋 로드\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)\n",
    "# 데이터 전처리\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.fit_transform(y_test)\n",
    "# 시퀀스 패딩\n",
    "max_sequence_length = 100  # 시퀀스의 최대 길이 지정\n",
    "x_train = pad_sequences(x_train, maxlen=max_sequence_length)\n",
    "x_test = pad_sequences(x_test, maxlen=max_sequence_length)\n",
    "# 모델 구성\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=10000, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(units=46, activation='softmax'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=30, validation_data=(x_test, y_test))\n",
    "\n",
    "# 테스트 데이터에 대한 예측\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# 분류 보고서 출력\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "report = classification_report(y_test_labels, y_pred_labels)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
